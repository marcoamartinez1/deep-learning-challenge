{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae9590f-43f4-45e7-8984-fb4381367218",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Overview #\n",
    "The purpose of this analysis is to use data from a non-profit, Alphabet Soup, that provides funding to other organizations. This data will train a model that can be used to determine potential successful applications in the future.\n",
    "Results\n",
    "## Preprocessing\n",
    "### What variable(s) are the target(s) for your model?\n",
    "The target variable for my model is the “IS_SUCCESSFUL” column, which indicates whether or not a given group achieved its funding goal.\n",
    "### What variable(s) are the features for your model?\n",
    "The features are “APPLICATION_TYPE,” “AFFILIATION,” “CLASSIFICATION,” “USE_CASE,” “ORGANIZATION,” “STATUS,” “INCOME_AMT,” “SPECIAL_CONSIDERATIONS,” and “ASK_AMT.”\n",
    "### What variable(s) should be removed from the input data because they are neither targets nor features?\n",
    "“EIN” and “NAME” are purely descriptive and were removed.\n",
    "## Compiling, Training, and Evaluating the Model\n",
    "### How many neurons, layers, and activation functions did you select for your neural network model, and why?\n",
    "In the original model, I used two hidden layers and one output layer.\n",
    "The first layer contained eight nodes and the second layer contained six.\n",
    "I used the in-class activities as a reference for these. I also do some research on Stack Overflow and Stack Exchange and I got the impression that the number of neurons chosen for a model is somewhat arbitrary. However, I kept in mind the possibility of overfitting the model to the data. I felt eight and six were sufficient.\n",
    "### Were you able to achieve the target model performance?\n",
    "I did not eachieve the target model performance. My model only reached 72.5% accuracy.\n",
    "### What steps did you take in your attempts to increase model performance?\n",
    "I created two other models to see if I could break the 75% threshold.\n",
    "#### Adjustments made in the “optimized” model:\n",
    "- “APPLICATION_TYPE” value\n",
    "I changed the threshold for which application types were assigned “other” from counts of 200 to counts of 1000. This means that only application types that occurred more 1000 times would be included, the rest were changed to “other.”\n",
    "- “CLASSIFICATION” value\n",
    "I changed the threshold for which classifications were assigned “other” from counts of 1750 to counts of 2000. This means that only classification values that occurred more 2000 times would be included, the rest were changed to “other.”\n",
    "Moved it from 1750 to 2000\n",
    "- “ASK_AMT” value\n",
    "I noticed there were 8747 different values in the ASK_AMT column, but the count for an ask amount of 5000 was 25,398. I was curious if the model would be more accurate if I considered just the funding goals of 5000. So, I set all other ask amounts to “other.”\n",
    "- 200 epochs\n",
    "Instead of 100 epochs, I used 200 epochs. This doubles the training time and would hopefully increase the accuracy.\n",
    "- Added more neurons, 10 for each layer\n",
    "I added 10 neurons to each layer to see if that would boost accuracy.\n",
    "- Addded a third hidden layer\n",
    "I added a third hidden layer to see if that would help with accuracy.\n",
    "#### Did these adjustments work?\n",
    "No, the model accuracy was 72.2%. This is marginally less than the original. \n",
    "### Original Code\n",
    "![](file:///Users/marcomartinez/Desktop/Screenshot%202024-08-03%20at%203.19.01%E2%80%AFPM.png)\n",
    "### Optimized Code\n",
    "![](file:///Users/marcomartinez/Desktop/Screenshot%202024-08-03%20at%203.20.34%E2%80%AFPM.png)\n",
    "\n",
    "\n",
    "## Summary\n",
    "In both cases, the models I created did not meet the 75% threshold. This means both models are unreliable and should not be used by Alphabet Soup. Neither model will provide a strong indicator of what types of organizations or campaigns will succeed. I expected the second model to perform better as I was comparing records with ask amounts of 5000 to the rest of the population. This was not enough of a change to make the model reliable, evidently.\n",
    "\n",
    "Instead of a neural network, a decision tree could be useful in achieving a more reliable model. Decision trees are versatile in that they can handle both numerical and categorical data. This data set has these both of these types of values. Similarly, decision trees can capture non-linear relationships between features and target variables. Another advantage is to that decision trees can provide insight into the importance of certain features. Such a characteristic could help Alphabet Soup in understanding what factors lead to successful campaigns.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
